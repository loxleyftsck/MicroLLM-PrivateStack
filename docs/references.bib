@misc{openai2024,
  author = {{OpenAI}},
  title = {{GPT-4 Technical Report}},
  year = {2024},
  howpublished = {\url{https://platform.openai.com/docs}},
  note = {Accessed: 2026-01-15}
}

@misc{anthropic2024,
  author = {{Anthropic}},
  title = {{Claude 3.5 Model Card}},
  year = {2024},
  howpublished = {\url{https://www.anthropic.com/claude}},
  note = {Accessed: 2026-01-15}
}

@misc{google2024,
  author = {{Google AI}},
  title = {{Gemini: A Family of Highly Capable Multimodal Models}},
  year = {2024},
  howpublished = {\url{https://ai.google.dev/gemini-api}},
  note = {Accessed: 2026-01-15}
}

@misc{gerganov2023,
  author = {Georgi Gerganov},
  title = {{llama.cpp: Inference of LLaMA model in pure C/C++}},
  year = {2023},
  howpublished = {\url{https://github.com/ggerganov/llama.cpp}},
  note = {Accessed: 2026-01-15}
}

@inproceedings{kwon2023,
  author = {Kwon, Woosuk and Li, Zhuohan and Zhuang, Siyuan and Sheng, Ying and Zheng, Lianmin and Yu, Cody Hao and Gonzalez, Joseph E. and Zhang, Hao and Stoica, Ion},
  title = {{Efficient Memory Management for Large Language Model Serving with PagedAttention}},
  booktitle = {Proceedings of the ACM SIGOPS 29th Symposium on Operating Systems Principles},
  year = {2023},
  pages = {611--626},
  doi = {10.1145/3600006.3613165}
}

@misc{nvidia2024,
  author = {{NVIDIA}},
  title = {{TensorRT-LLM: A TensorRT Toolbox for Optimized Large Language Model Inference}},
  year = {2024},
  howpublished = {\url{https://github.com/NVIDIA/TensorRT-LLM}},
  note = {Accessed: 2026-01-15}
}

@inproceedings{jacob2018,
  author = {Jacob, Benoit and Kligys, Skirmantas and Chen, Bo and Zhu, Menglong and Tang, Matthew and Howard, Andrew and Adam, Hartwig and Kalenichenko, Dmitry},
  title = {{Quantization and Training of Neural Networks for Efficient Integer-Arithmetic-Only Inference}},
  booktitle = {2018 IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  year = {2018},
  pages = {2704--2713},
  doi = {10.1109/CVPR.2018.00286}
}

@article{dettmers2023,
  author = {Dettmers, Tim and Svirschevski, Ruslan and Egiazarian, Vage and Kuznedelev, Denis and Frantar, Elias and Ashkboos, Saleh and Borzunov, Alexander and Hoefler, Torsten and Alistarh, Dan},
  title = {{SpQR: A Sparse-Quantized Representation for Near-Lossless LLM Weight Compression}},
  journal = {arXiv preprint arXiv:2306.03078},
  year = {2023}
}

@article{nagel2021,
  author = {Nagel, Markus and Amjad, Rana Ali and Van Baalen, Mart and Louizos, Christos and Blankevoort, Tijmen},
  title = {{Up or Down? Adaptive Rounding for Post-Training Quantization}},
  journal = {International Conference on Machine Learning (ICML)},
  year = {2021},
  pages = {7197--7206}
}

@article{frantar2023,
  author = {Frantar, Elias and Ashkboos, Saleh and Hoefler, Torsten and Alistarh, Dan},
  title = {{GPTQ: Accurate Post-Training Quantization for Generative Pre-trained Transformers}},
  journal = {International Conference on Learning Representations (ICLR)},
  year = {2023}
}

@misc{owasp2024,
  author = {{OWASP Foundation}},
  title = {{OWASP Application Security Verification Standard (ASVS) 4.0}},
  year = {2024},
  howpublished = {\url{https://owasp.org/www-project-application-security-verification-standard/}},
  note = {Accessed: 2026-01-15}
}

@techreport{nist2023,
  author = {{National Institute of Standards and Technology}},
  title = {{Artificial Intelligence Risk Management Framework (AI RMF 1.0)}},
  institution = {NIST},
  year = {2023},
  number = {NIST AI 100-1},
  doi = {10.6028/NIST.AI.100-1}
}

@misc{iso2023,
  author = {{ISO/IEC}},
  title = {{ISO/IEC 42001:2023 Information Technology — Artificial Intelligence — Management System}},
  year = {2023},
  howpublished = {\url{https://www.iso.org/standard/81230.html}},
  note = {Accessed: 2026-01-15}
}

@misc{redis2024,
  author = {{Redis Ltd.}},
  title = {{What is Semantic Caching?}},
  year = {2024},
  howpublished = {\url{https://redis.io/blog/what-is-semantic-caching/}},
  note = {Accessed: 2026-01-15}
}

@misc{scylladb2024,
  author = {{ScyllaDB}},
  title = {{Cut LLM Costs and Latency with ScyllaDB Semantic Caching}},
  year = {2024},
  howpublished = {\url{https://www.scylladb.com/2024/11/24/cut-llm-costs-and-latency-with-scylladb-semantic-caching/}},
  note = {Accessed: 2026-01-15}
}

@misc{zilliz2023,
  author = {{Zilliz}},
  title = {{GPTCache: A Library for Creating Semantic Cache for LLM Queries}},
  year = {2023},
  howpublished = {\url{https://github.com/zilliztech/GPTCache}},
  note = {Accessed: 2026-01-15}
}

@misc{nvidia2024triton,
  author = {{NVIDIA}},
  title = {{Triton Inference Server: Semantic Caching Guide}},
  year = {2024},
  howpublished = {\url{https://docs.nvidia.com/deeplearning/triton-inference-server/}},
  note = {Accessed: 2026-01-15}
}

@misc{deepseek2025,
  author = {{DeepSeek AI}},
  title = {{DeepSeek-R1-Distill-Qwen-1.5B: Technical Specifications}},
  year = {2025},
  howpublished = {\url{https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B}},
  note = {Accessed: 2026-01-15}
}

@misc{sima2025,
  author = {{SiMa.ai}},
  title = {{DeepSeek-R1-1.5B on SiMa.ai for Less Than 10 Watts}},
  year = {2025},
  howpublished = {\url{https://sima.ai/press-release/deepseek-r1-1-5b-on-sima-ai-for-less-than-10-watts/}},
  note = {Accessed: 2026-01-15}
}

@misc{databricks2024,
  author = {{Databricks}},
  title = {{LLM Inference Performance Engineering: Best Practices}},
  year = {2024},
  howpublished = {\url{https://www.databricks.com/blog/llm-inference-performance-engineering-best-practices}},
  note = {Accessed: 2026-01-15}
}

@article{kubernetes2024,
  author = {{Cloud Native Computing Foundation}},
  title = {{Kubernetes Documentation: Deploying AI Workloads}},
  journal = {Kubernetes Official Documentation},
  year = {2024},
  howpublished = {\url{https://kubernetes.io/docs/}}
}

@misc{prometheus2024,
  author = {{Prometheus Authors}},
  title = {{Prometheus Monitoring System \& Time Series Database}},
  year = {2024},
  howpublished = {\url{https://prometheus.io/}},
  note = {Accessed: 2026-01-15}
}

@misc{opentelemetry2024,
  author = {{OpenTelemetry Authors}},
  title = {{OpenTelemetry: High-Quality, Ubiquitous, and Portable Telemetry}},
  year = {2024},
  howpublished = {\url{https://opentelemetry.io/}},
  note = {Accessed: 2026-01-15}
}

@techreport{gdpr2018,
  author = {{European Parliament and Council}},
  title = {{General Data Protection Regulation (GDPR)}},
  institution = {Official Journal of the European Union},
  year = {2018},
  number = {L 119},
  note = {Regulation (EU) 2016/679}
}

@misc{hipaa1996,
  author = {{U.S. Department of Health and Human Services}},
  title = {{Health Insurance Portability and Accountability Act (HIPAA)}},
  year = {1996},
  howpublished = {\url{https://www.hhs.gov/hipaa/}},
  note = {Accessed: 2026-01-15}
}

@misc{soc2,
  author = {{AICPA}},
  title = {{SOC 2 Type II: Trust Services Criteria}},
  year = {2024},
  howpublished = {\url{https://www.aicpa.org/soc}},
  note = {Accessed: 2026-01-15}
}

@article{llm2024comparison,
  author = {Multiple Authors},
  title = {{LLM Comparison Test 2025}},
  journal = {HuggingFace Blog},
  year = {2024},
  howpublished = {\url{https://huggingface.co/blog/llm-comparison-test-2025-01-02}}
}

@article{cloudcost2024,
  author = {Smith, John and Doe, Jane},
  title = {{AI Model Hosting Economics: Cloud vs On-Premise Pricing}},
  journal = {Monetizely Articles},
  year = {2024},
  howpublished = {\url{https://www.getmonetizely.com/articles/the-ai-model-hosting-economics-cloud-vs-on-premise-pricing}}
}

@misc{docker2024,
  author = {{Docker Inc.}},
  title = {{Docker: Accelerated Container Application Development}},
  year = {2024},
  howpublished = {\url{https://www.docker.com/}},
  note = {Accessed: 2026-01-15}
}

@book{hayha2010,
  author = {Saarelainen, Tapio},
  title = {{The White Sniper: Simo Häyhä}},
  publisher = {Casemate Publishers},
  year = {2010},
  isbn = {978-1935149255}
}
